{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**6.Sentiment analysis using LSTM network or GRU.**  "
      ],
      "metadata": {
        "id": "kbLdyHuyZPmg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKsFnO2IV4_X",
        "outputId": "83ff1eeb-f964-437e-e1aa-e3ea2cc8565d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     name\n",
            "0  Tweets\n",
            "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
            "0  567588278875213824           neutral                           1.0   \n",
            "1  567590027375702016          negative                           1.0   \n",
            "2  567591480085463040          negative                           1.0   \n",
            "3  567592368451248130          negative                           1.0   \n",
            "4  567594449874587648          negative                           1.0   \n",
            "\n",
            "           negativereason negativereason_confidence    airline  \\\n",
            "0                                                        Delta   \n",
            "1              Can't Tell                    0.6503      Delta   \n",
            "2             Late Flight                     0.346     United   \n",
            "3             Late Flight                         1     United   \n",
            "4  Customer Service Issue                    0.3451  Southwest   \n",
            "\n",
            "  airline_sentiment_gold         name negativereason_gold  retweet_count  \\\n",
            "0                         JetBlueNews                                  0   \n",
            "1                           nesi_1992                                  0   \n",
            "2                           CPoutloud                                  0   \n",
            "3                            brenduch                                  0   \n",
            "4                            VahidESQ                                  0   \n",
            "\n",
            "                                                text tweet_coord  \\\n",
            "0  @JetBlue's new CEO seeks the right balance to ...               \n",
            "1  @JetBlue is REALLY getting on my nerves !! 😡😡 ...               \n",
            "2  @united yes. We waited in line for almost an h...               \n",
            "3  @united the we got into the gate at IAH on tim...               \n",
            "4  @SouthwestAir its cool that my bags take a bit...               \n",
            "\n",
            "               tweet_created   tweet_location               user_timezone  \n",
            "0  2015-02-16 23:36:05 -0800              USA                      Sydney  \n",
            "1  2015-02-16 23:43:02 -0800        undecided  Pacific Time (US & Canada)  \n",
            "2  2015-02-16 23:48:48 -0800   Washington, DC                              \n",
            "3  2015-02-16 23:52:20 -0800                                 Buenos Aires  \n",
            "4  2015-02-17 00:00:36 -0800  Los Angeles, CA  Pacific Time (US & Canada)  \n"
          ]
        }
      ],
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "# Connect to the SQLite database\n",
        "conn = sqlite3.connect(\"database.sqlite\")\n",
        "\n",
        "# See what tables are inside\n",
        "print(pd.read_sql(\"SELECT name FROM sqlite_master WHERE type='table';\", conn))\n",
        "\n",
        "# Load the main table (usually called 'Tweets')\n",
        "df = pd.read_sql(\"SELECT * FROM Tweets\", conn)\n",
        "\n",
        "# Show some rows\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep only tweet text and sentiment\n",
        "# data = df[['airline_sentiment', 'text']] # No longer needed\n",
        "\n",
        "# Encode labels as numbers\n",
        "df['label'] = df['airline_sentiment'].map({'negative':0, 'neutral':1, 'positive':2})"
      ],
      "metadata": {
        "id": "js91zh42WlqD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split into Train and Test Sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['text'], df['label'], test_size=0.2, random_state=42, stratify=df['label'])\n"
      ],
      "metadata": {
        "id": "EzYYetBEWoZU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenize and Pad Sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "vocab_size = 10000\n",
        "maxlen = 50\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=maxlen, padding='post')\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=maxlen, padding='post')\n"
      ],
      "metadata": {
        "id": "7NtoT2JWXWDw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build the LSTM or GRU Model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense, Dropout\n",
        "\n",
        "num_classes = 3  # negative, neutral, positive\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, 128, input_length=maxlen),\n",
        "    LSTM(128, dropout=0.2, recurrent_dropout=0.2),  # or GRU(128,...)\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "YbBLt0X-Xb3X",
        "outputId": "6b03f46f-67cb-438d-ee77-77a06cd99a39"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Train The Model\n",
        "history = model.fit(\n",
        "    X_train_pad, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=5,\n",
        "    batch_size=64\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wS3E1a-GX4Si",
        "outputId": "859d9164-9e56-4205-ddba-b4225d5d43bd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 172ms/step - accuracy: 0.6240 - loss: 0.9399 - val_accuracy: 0.6665 - val_loss: 0.7659\n",
            "Epoch 2/5\n",
            "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 159ms/step - accuracy: 0.6679 - loss: 0.7402 - val_accuracy: 0.7010 - val_loss: 0.6597\n",
            "Epoch 3/5\n",
            "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 162ms/step - accuracy: 0.7361 - loss: 0.5872 - val_accuracy: 0.6739 - val_loss: 0.6764\n",
            "Epoch 4/5\n",
            "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 172ms/step - accuracy: 0.7523 - loss: 0.5234 - val_accuracy: 0.7092 - val_loss: 0.6668\n",
            "Epoch 5/5\n",
            "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 162ms/step - accuracy: 0.7667 - loss: 0.4773 - val_accuracy: 0.7282 - val_loss: 0.7749\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the Model\n",
        "loss, acc = model.evaluate(X_test_pad, y_test)\n",
        "print(f\"Test Accuracy: {acc:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8XXhnAZX6oV",
        "outputId": "d3ac33a8-41f3-4dad-992b-758af73eb78e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.7428 - loss: 0.7303\n",
            "Test Accuracy: 0.74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Some new unseen tweets to test\n",
        "new_tweets = [\n",
        "    \"The flight was delayed for 3 hours and staff were rude.\",\n",
        "    \"Excellent service, on-time flight and friendly crew!\",\n",
        "    \"It was okay, nothing special but nothing bad either.\",\n",
        "    \"Lost my luggage again. So frustrating!\",\n",
        "    \"Loved the extra legroom seats, super comfortable.\"\n",
        "]\n",
        "\n",
        "# Convert text to sequences using the same tokenizer used for training\n",
        "seqs = tokenizer.texts_to_sequences(new_tweets)\n",
        "\n",
        "# Pad sequences to the same maxlen as training data\n",
        "pads = pad_sequences(seqs, maxlen=maxlen, padding='post')\n",
        "\n",
        "# Predict sentiment for each tweet\n",
        "preds = model.predict(pads)\n",
        "\n",
        "# Map predicted label numbers back to sentiment names\n",
        "sentiments = ['negative', 'neutral', 'positive']\n",
        "\n",
        "for tweet, p in zip(new_tweets, preds):\n",
        "    print(f\"Tweet: {tweet}\")\n",
        "    print(f\"Predicted Sentiment: {sentiments[p.argmax()]}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5z87OItYYP7",
        "outputId": "20ec7187-ef1a-409f-96fe-75922631315f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639ms/step\n",
            "Tweet: The flight was delayed for 3 hours and staff were rude.\n",
            "Predicted Sentiment: negative\n",
            "--------------------------------------------------\n",
            "Tweet: Excellent service, on-time flight and friendly crew!\n",
            "Predicted Sentiment: positive\n",
            "--------------------------------------------------\n",
            "Tweet: It was okay, nothing special but nothing bad either.\n",
            "Predicted Sentiment: negative\n",
            "--------------------------------------------------\n",
            "Tweet: Lost my luggage again. So frustrating!\n",
            "Predicted Sentiment: negative\n",
            "--------------------------------------------------\n",
            "Tweet: Loved the extra legroom seats, super comfortable.\n",
            "Predicted Sentiment: neutral\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}