{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Be1Exegg04Fb"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import cv2, os\n",
        "import numpy as np\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "    js = '''\n",
        "      async function takePhoto(quality) {\n",
        "        const div = document.createElement('div');\n",
        "        const capture = document.createElement('button');\n",
        "        capture.textContent = '📸 Capture';\n",
        "        div.appendChild(capture);\n",
        "\n",
        "        const video = document.createElement('video');\n",
        "        video.style.display = 'block';\n",
        "        div.appendChild(video);\n",
        "\n",
        "        document.body.appendChild(div);\n",
        "\n",
        "        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "        video.srcObject = stream;\n",
        "        await video.play();\n",
        "\n",
        "        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "        await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "        const canvas = document.createElement('canvas');\n",
        "        canvas.width = video.videoWidth;\n",
        "        canvas.height = video.videoHeight;\n",
        "        canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "        stream.getTracks().forEach(track => track.stop());\n",
        "        div.remove();\n",
        "\n",
        "        const dataUrl = canvas.toDataURL('image/jpeg', quality);\n",
        "        return dataUrl;\n",
        "      }\n",
        "      takePhoto({quality: %f});\n",
        "    ''' % quality\n",
        "    data = eval_js(js)\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(binary)\n",
        "    return filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swe_SioW07ij"
      },
      "outputs": [],
      "source": [
        "os.makedirs(\"dataset/me\", exist_ok=True)\n",
        "os.makedirs(\"dataset/friend\", exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "dl81nELU1Bi0",
        "outputId": "a3417c1c-2b47-40fc-c9df-9ce3db1bbd4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved dataset/me/me_1.jpg\n",
            "Saved dataset/me/me_2.jpg\n",
            "Saved dataset/me/me_3.jpg\n",
            "Saved dataset/me/me_4.jpg\n",
            "Saved dataset/me/me_5.jpg\n",
            "Saved dataset/me/me_6.jpg\n",
            "Saved dataset/me/me_7.jpg\n",
            "Saved dataset/me/me_8.jpg\n",
            "Saved dataset/me/me_9.jpg\n",
            "Saved dataset/me/me_10.jpg\n"
          ]
        }
      ],
      "source": [
        "#For me\n",
        "for i in range(1, 11):   # change 11 → 51 if you want 50 photos\n",
        "    filename = take_photo(f\"dataset/me/me_{i}.jpg\")\n",
        "    print(\"Saved\", filename)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "hxqbnmeG1ch5",
        "outputId": "8cc71f43-e291-4bd6-8309-735b84228efd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved dataset/friend/friend_1.jpg\n",
            "Saved dataset/friend/friend_2.jpg\n",
            "Saved dataset/friend/friend_3.jpg\n",
            "Saved dataset/friend/friend_4.jpg\n",
            "Saved dataset/friend/friend_5.jpg\n",
            "Saved dataset/friend/friend_6.jpg\n",
            "Saved dataset/friend/friend_7.jpg\n",
            "Saved dataset/friend/friend_8.jpg\n",
            "Saved dataset/friend/friend_9.jpg\n",
            "Saved dataset/friend/friend_10.jpg\n"
          ]
        }
      ],
      "source": [
        "#Take your images through webscam\n",
        "for i in range(1, 11):   # change 11 → 51 if you want 50 photos\n",
        "    filename = take_photo(f\"dataset/friend/friend_{i}.jpg\")\n",
        "    print(\"Saved\", filename)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ii0M_e6f152R",
        "outputId": "e0eb5154-a97b-4365-a22c-20e1480a4255"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "My images: 10\n",
            "Friend images: 10\n"
          ]
        }
      ],
      "source": [
        "#Take friend images through web\n",
        "import glob\n",
        "print(\"My images:\", len(glob.glob(\"dataset/me/*.jpg\")))\n",
        "print(\"Friend images:\", len(glob.glob(\"dataset/friend/*.jpg\")))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mo1vFvlq1-jF",
        "outputId": "a35e962a-de79-4f2b-df9c-968658b6f04f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset shape: (20, 128, 128, 3) Labels: (20,)\n"
          ]
        }
      ],
      "source": [
        "#Preprocess images\n",
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "\n",
        "IMG_SIZE = 128\n",
        "X, y = [], []\n",
        "\n",
        "def load_images(folder, label):\n",
        "    data, labels = [], []\n",
        "    for file in glob.glob(folder + \"/*.jpg\"):\n",
        "        img = cv2.imread(file)\n",
        "        if img is None:  # skip bad images\n",
        "            continue\n",
        "        # Face detection (optional but better)\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "\n",
        "        if len(faces) > 0:\n",
        "            x,yc,w,h = faces[0]\n",
        "            img = img[yc:yc+h, x:x+w]  # crop face\n",
        "\n",
        "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "        data.append(img)\n",
        "        labels.append(label)\n",
        "    return data, labels\n",
        "\n",
        "me_data, me_labels = load_images(\"dataset/me\", 0)       # Label 0 = Me\n",
        "friend_data, friend_labels = load_images(\"dataset/friend\", 1) # Label 1 = Friend\n",
        "\n",
        "X = np.array(me_data + friend_data) / 255.0\n",
        "y = np.array(me_labels + friend_labels)\n",
        "\n",
        "print(\"Dataset shape:\", X.shape, \"Labels:\", y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uqy2gYV2rys"
      },
      "outputs": [],
      "source": [
        "#Train-Test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuUtfvKX2yRw",
        "outputId": "1881c4be-c958-4b6e-ba3f-cea8159d0acd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.5625 - loss: 0.6947 - val_accuracy: 0.7500 - val_loss: 0.4956\n",
            "Epoch 2/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858ms/step - accuracy: 0.5625 - loss: 0.6502 - val_accuracy: 0.5000 - val_loss: 1.6297\n",
            "Epoch 3/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495ms/step - accuracy: 0.5000 - loss: 1.5448 - val_accuracy: 1.0000 - val_loss: 0.3360\n",
            "Epoch 4/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 521ms/step - accuracy: 0.8750 - loss: 0.2949 - val_accuracy: 0.5000 - val_loss: 0.7095\n",
            "Epoch 5/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460ms/step - accuracy: 0.6250 - loss: 0.5629 - val_accuracy: 0.7500 - val_loss: 0.4161\n",
            "Epoch 6/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step - accuracy: 0.8750 - loss: 0.2831 - val_accuracy: 1.0000 - val_loss: 0.1447\n",
            "Epoch 7/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 518ms/step - accuracy: 1.0000 - loss: 0.0680 - val_accuracy: 1.0000 - val_loss: 0.1660\n",
            "Epoch 8/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656ms/step - accuracy: 1.0000 - loss: 0.0780 - val_accuracy: 1.0000 - val_loss: 0.2056\n",
            "Epoch 9/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495ms/step - accuracy: 1.0000 - loss: 0.0845 - val_accuracy: 1.0000 - val_loss: 0.1181\n",
            "Epoch 10/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step - accuracy: 1.0000 - loss: 0.0300 - val_accuracy: 1.0000 - val_loss: 0.0431\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(1, activation='sigmoid')  # Binary output\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuc175u422_E",
        "outputId": "70b43bb7-4af8-4759-8d84-f2d9e8396dd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 0.0431\n",
            "Test Accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {acc*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = take_photo(\"test.jpg\")\n",
        "\n",
        "img = cv2.imread(filename)\n",
        "img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "img = np.expand_dims(img/255.0, axis=0)\n",
        "\n",
        "prediction = model.predict(img)[0][0]\n",
        "\n",
        "# Add threshold logic\n",
        "if prediction < 0.3:\n",
        "    print(\"Prediction: It's YOU 😃\")\n",
        "elif prediction > 0.7:\n",
        "    print(\"Prediction: It's YOUR FRIEND 👯\")\n",
        "else:\n",
        "    print(\"Prediction: It's a DIFFERENT PERSON 🕵️\")\n"
      ],
      "metadata": {
        "id": "2A4WhR797eKa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "07d23c87-46d1-4de4-8273-1ddadbc07644"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "Prediction: It's a DIFFERENT PERSON 🕵️\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}